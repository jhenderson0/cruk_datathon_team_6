{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cruk_datathon/lib/python3.12/site-packages/logomaker/../tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyrepseq as prs\n",
    "import tidytcells as tt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move to correct directory\n",
    "os.chdir('/Users/isabellasodi/Documents/UCL/PhD/CRUK_datathon_2025')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "#tcr_data = pd.read_csv('input/tcrictionary_tabular.csv' )\n",
    "tcr_data_raw = pd.read_csv('/Volumes/ritd-ag-project-rd0017-bmcha43/CRUK_datathon_2025/raw_data/tcrictionary_tabular.csv' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand out so that each study is a row\n",
    "tcr_data = tcr_data_raw.assign(Studies=tcr_data_raw['Studies'].str.split(',')).explode('Studies')\n",
    "tcr_data = tcr_data.reset_index(drop=True)\n",
    "tcr_data['Studies'] = tcr_data['Studies'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove anything after a + for some epitopes with PTM info\n",
    "tcr_data['epitope'] = tcr_data['epitope'].str.split('+').str[0].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove *,  and X (based on amino acids) in alpha chain \n",
    "# use tidy t cells, go through and remove cells with not allowed\n",
    "tcr_data['CDR3A'] = tcr_data['CDR3A'].apply(lambda x: tt.aa.standardize(x, log_failures=False) if pd.notna(x) else x)\n",
    "tcr_data['CDR3B'] = tcr_data['CDR3B'].apply(lambda x: tt.aa.standardize(x, log_failures=False) if pd.notna(x) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Left\n",
      "epitopes: 2069\n",
      "beta: 156662 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# only human\n",
    "tcr_data = tcr_data[ tcr_data['TCR species'] == 'HomoSapiens'].copy()\n",
    "\n",
    "# only with epitopes\n",
    "tcr_data = tcr_data[ ~tcr_data['epitope'].isna()].copy()\n",
    "\n",
    "# only betas\n",
    "tcr_data = tcr_data[ ~tcr_data['CDR3B'].isna()].copy()\n",
    "\n",
    "# only class 1\n",
    "tcr_data = tcr_data[tcr_data['MHC class'] == 1]\n",
    "tcr_data\n",
    "\n",
    "print('Unique Left')\n",
    "print('epitopes:', tcr_data['epitope'].nunique())\n",
    "print('beta:', tcr_data['CDR3B'].nunique(), '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: \n",
      "beta: 15\n",
      "epitope: 9\n"
     ]
    }
   ],
   "source": [
    "# get stats\n",
    "tcr_data['CDR3B_length'] = tcr_data['CDR3B'].str.len().astype('Int64')\n",
    "tcr_data['epitope_length'] = tcr_data['epitope'].str.len().astype('Int64')\n",
    "\n",
    "mode_CDR3B = tcr_data['CDR3B_length'].value_counts().index[0]\n",
    "mode_epitope = tcr_data['epitope_length'].value_counts().index[0]\n",
    "\n",
    "print('Mode: ')\n",
    "print('beta:', mode_CDR3B)\n",
    "print('epitope:', mode_epitope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Left\n",
      "epitopes: 757\n",
      "beta: 18205 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tcr_data_unfiltered = tcr_data.copy() # save unfiltered just in case\n",
    "\n",
    "tcr_data = tcr_data[tcr_data['CDR3B_length'] == mode_CDR3B]\n",
    "tcr_data = tcr_data[tcr_data['epitope_length'] == mode_epitope]\n",
    "\n",
    "print('Unique Left')\n",
    "print('epitopes:', tcr_data['epitope'].nunique())\n",
    "print('beta:', tcr_data['CDR3B'].nunique(), '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "epitopes: 754\n",
      "beta: 18196 \n",
      "\n",
      "Cancer\n",
      "epitopes: 3\n",
      "beta: 10\n"
     ]
    }
   ],
   "source": [
    "# remove cancer studies\n",
    "cancer_studies = ['PMID:38039963', 'PMID:27959684', 'PMID:32461371']\n",
    "#study_pattern = '|'.join(cancer_studies)\n",
    "\n",
    "tcr_data_cancer = tcr_data[ tcr_data['Studies'].isin(cancer_studies)] # need to do str match for multiple studies\n",
    "#tcr_data_cancer = tcr_data[tcr_data['Studies'].str.contains(study_pattern, na=False)] # no need as now expanded\n",
    "\n",
    "tcr_data_train = tcr_data[ ~tcr_data['Studies'].isin(cancer_studies)]\n",
    "#tcr_data_train = tcr_data[~tcr_data['Studies'].str.contains(study_pattern, na=False)]\n",
    "\n",
    "print('Training')\n",
    "print('epitopes:', tcr_data_train['epitope'].nunique())\n",
    "print('beta:', tcr_data_train['CDR3B'].nunique(), '\\n')\n",
    "\n",
    "print('Cancer')\n",
    "print('epitopes:', tcr_data_cancer['epitope'].nunique())\n",
    "print('beta:', tcr_data_cancer['CDR3B'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NENLDLKEL' 'NENLDLQEL' 'GADGVGKSA']\n",
      "3\n",
      "leaking epitopes: 0\n",
      "Series([], Name: epitope, dtype: object) \n",
      "\n",
      "Training\n",
      "epitopes: 754\n",
      "beta: 18196 \n",
      "\n",
      "Cancer (w/ leaking)\n",
      "epitopes: 3\n",
      "beta: 10\n"
     ]
    }
   ],
   "source": [
    "# check if cancer epitopes are in train\n",
    "\n",
    "cancer_epitopes = tcr_data_cancer['epitope'].unique()\n",
    "print(cancer_epitopes)\n",
    "print( len(cancer_epitopes))\n",
    "\n",
    "epitope_pattern = '|'.join(cancer_epitopes)\n",
    "leaking_epitopes = tcr_data_train[tcr_data_train['epitope'].str.contains(epitope_pattern, na=False)]\n",
    "\n",
    "print('leaking epitopes:', len(leaking_epitopes))\n",
    "print( leaking_epitopes['epitope'], '\\n')\n",
    "\n",
    "# remove leaking epitopes in train\n",
    "tcr_data_train = tcr_data_train[~tcr_data_train['epitope'].str.contains(epitope_pattern, na=False)]\n",
    "tcr_data_train\n",
    "\n",
    "# add leaking epitopes to validate\n",
    "tcr_data_cancer = pd.concat([tcr_data_cancer, leaking_epitopes])\n",
    "\n",
    "print('Training')\n",
    "print('epitopes:', tcr_data_train['epitope'].nunique())\n",
    "print('beta:', tcr_data_train['CDR3B'].nunique(), '\\n')\n",
    "\n",
    "print('Cancer (w/ leaking)')\n",
    "print('epitopes:', tcr_data_cancer['epitope'].nunique())\n",
    "print('beta:', tcr_data_cancer['CDR3B'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique epitopes in train/test: 754 \n",
      "\n",
      "Unique epitopes in test: 75 \n",
      "\n",
      "Training (unique)\n",
      "epitopes: 679\n",
      "beta: 17149\n",
      "total: 402753 \n",
      "\n",
      "Test (unique)\n",
      "epitopes: 75\n",
      "beta: 1105\n",
      "total: 16887\n"
     ]
    }
   ],
   "source": [
    "# remove additional 10% of epitopes\n",
    "all_epitopes = tcr_data_train[['epitope', 'epitope_length']].drop_duplicates()\n",
    "print('Unique epitopes in train/test:', tcr_data_train['epitope'].nunique(), '\\n')\n",
    "\n",
    "test_epitopes = all_epitopes.sample( round(len(all_epitopes)*0.1 ), random_state=27)\n",
    "print('Unique epitopes in test:', test_epitopes['epitope'].nunique(), '\\n')\n",
    "# validation_random_epitopes['epitope'].nunique() # not sure why has 193\n",
    "\n",
    "tcr_data_test = tcr_data_train[ tcr_data_train['epitope'].isin(test_epitopes['epitope'])]\n",
    "\n",
    "assert test_epitopes['epitope'].nunique() == 75\n",
    "\n",
    "tcr_data_train = tcr_data_train[ ~tcr_data_train['epitope'].isin(test_epitopes['epitope'])]\n",
    "\n",
    "print('Training (unique)')\n",
    "print('epitopes:', tcr_data_train['epitope'].nunique())\n",
    "print('beta:', tcr_data_train['CDR3B'].nunique())\n",
    "print('total:', tcr_data_train.size, '\\n')\n",
    "\n",
    "print('Test (unique)')\n",
    "print('epitopes:', tcr_data_test['epitope'].nunique())\n",
    "print('beta:', tcr_data_test['CDR3B'].nunique())\n",
    "print('total:', tcr_data_test.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epitopes: 75\n",
      "['FVDGVPFVV' 'FLRGRAYGL' 'FPRPWLHGL' 'YFPLQSYGF' 'NLIDSYFVV' 'CTELKLSDY'\n",
      " 'LLLGIGILV' 'VVLSWAPPV' 'LLYDANYFL']\n",
      "leaking epitopes: <bound method IndexOpsMixin.nunique of Series([], Name: epitope, dtype: object)>\n",
      "<bound method Series.unique of Series([], Name: epitope, dtype: object)> \n",
      "\n",
      "Training\n",
      "epitopes: 679\n",
      "beta: 17149 \n",
      "\n",
      "Test (w/ leaking)\n",
      "epitopes: 75\n",
      "beta: 1105\n"
     ]
    }
   ],
   "source": [
    "# check if test epitopes are in train (leaking)\n",
    "\n",
    "test_epitopes = tcr_data_test['epitope'].unique()\n",
    "print('test epitopes:', len(test_epitopes))\n",
    "print(test_epitopes[1:10])\n",
    "\n",
    "epitope_pattern = '|'.join(test_epitopes)\n",
    "leaking_epitopes = tcr_data_train[tcr_data_train['epitope'].str.contains(epitope_pattern, na=False)]\n",
    "\n",
    "print('leaking epitopes:', leaking_epitopes['epitope'].nunique)\n",
    "print( leaking_epitopes['epitope'].unique, '\\n')\n",
    "\n",
    "# remove leaking epitopes in train\n",
    "tcr_data_train = tcr_data_train[~tcr_data_train['epitope'].str.contains(epitope_pattern, na=False)]\n",
    "tcr_data_train\n",
    "\n",
    "# add leaking epitopes to validate\n",
    "tcr_data_test = pd.concat([tcr_data_test, leaking_epitopes])\n",
    "\n",
    "print('Training')\n",
    "print('epitopes:', tcr_data_train['epitope'].nunique())\n",
    "print('beta:', tcr_data_train['CDR3B'].nunique(), '\\n')\n",
    "\n",
    "print('Test (w/ leaking)')\n",
    "print('epitopes:', tcr_data_test['epitope'].nunique())\n",
    "print('beta:', tcr_data_test['CDR3B'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "epitopes: 679\n",
      "alpha: 5455\n",
      "beta: 17149 \n",
      "\n",
      "Test\n",
      "epitopes: 75\n",
      "alpha: 145\n",
      "beta: 1105 \n",
      "\n",
      "Cancer Test\n",
      "epitopes: 3\n",
      "alpha: 10\n",
      "beta: 10\n"
     ]
    }
   ],
   "source": [
    "print('Training')\n",
    "print('epitopes:', tcr_data_train['epitope'].nunique())\n",
    "print('beta:', tcr_data_train['CDR3B'].nunique(), '\\n')\n",
    "print('total:', tcr_data_train.size)\n",
    "\n",
    "print('Test')\n",
    "print('epitopes:', tcr_data_test['epitope'].nunique())\n",
    "print('beta:', tcr_data_test['CDR3B'].nunique(), '\\n')\n",
    "print('total:', tcr_data_test.size)\n",
    "\n",
    "print('Cancer Test')\n",
    "print('epitopes:', tcr_data_cancer['epitope'].nunique())\n",
    "print('beta:', tcr_data_cancer['CDR3B'].nunique())\n",
    "print('total:', tcr_data_test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcr_data_train.to_csv(f'/Volumes/ritd-ag-project-rd0017-bmcha43/CRUK_datathon_2025/processed_data/train_fixed_lengths.csv')\n",
    "tcr_data_test.to_csv(f'/Volumes/ritd-ag-project-rd0017-bmcha43/CRUK_datathon_2025/processed_data/test_fixed_lengths.csv')\n",
    "tcr_data_cancer.to_csv(f'/Volumes/ritd-ag-project-rd0017-bmcha43/CRUK_datathon_2025/processed_data/cancer_fixed_lengths.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cruk_datathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
