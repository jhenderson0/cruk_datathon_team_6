{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute reduced alphabet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhenderson/Documents/Projects/CI_CRUK_2025/venv/lib/python3.12/site-packages/logomaker/../tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyrepseq as prs\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/jhenderson/Documents/Projects/data_sets/tcr_sequences/CI_CRUK_datathon/'\n",
    "\n",
    "back = pd.read_csv(DATA_PATH + 'raw_data/olga_preprocessed.csv')\n",
    "\n",
    "test = pd.read_csv(DATA_PATH + 'processed_data/train.csv')\n",
    "test = test[['CDR3A', 'CDR3B', 'epitope', 'Assays']].dropna().reset_index(drop=True)\n",
    "\n",
    "tcr_info = pd.read_csv(DATA_PATH + 'raw_data/tcr_info_specific.csv') \n",
    "tcr_info = tcr_info.rename({'Epitope':'epitope'})\n",
    "\n",
    "aminoacids = 'ACDEFGHIKLMNPQRSTVWY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[test['Assays'].str.contains('mer')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "back.loc[:, 'CDR3A_length'] = back['CDR3A'].str.len().astype('Int64')\n",
    "back.loc[:, 'CDR3B_length'] = back['CDR3B'].str.len().astype('Int64')\n",
    "\n",
    "back = back[\n",
    "    (back['CDR3A_length'].isna()) |  # ignore NA values\n",
    "    (back['CDR3A_length'] >= 9) & \n",
    "    (back['CDR3A_length'] <= 18)\n",
    "]\n",
    "\n",
    "back = back[\n",
    "    (back['CDR3B_length'].isna()) |  # ignore NA values\n",
    "    (back['CDR3B_length'] >= 11) & \n",
    "    (back['CDR3B_length'] <= 18)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcr_info.loc[:, 'CDR3A_length'] = tcr_info['CDR3A'].str.len().astype('Int64')\n",
    "tcr_info.loc[:, 'CDR3B_length'] = tcr_info['CDR3B'].str.len().astype('Int64')\n",
    "\n",
    "tcr_info = tcr_info[\n",
    "    (tcr_info['CDR3A_length'].isna()) |  # ignore NA values\n",
    "    (tcr_info['CDR3A_length'] >= 9) & \n",
    "    (tcr_info['CDR3A_length'] <= 18)\n",
    "]\n",
    "\n",
    "tcr_info = tcr_info[\n",
    "    (tcr_info['CDR3B_length'].isna()) |  # ignore NA values\n",
    "    (tcr_info['CDR3B_length'] >= 11) & \n",
    "    (tcr_info['CDR3B_length'] <= 18)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_middle_five_left(aa_string):\n",
    "    if pd.isna(aa_string):  # Check for NaN/null values\n",
    "        return aa_string\n",
    "    length = len(aa_string)\n",
    "    \n",
    "    if( length % 2 == 0 ):\n",
    "            mid = length // 2 # integer division will ensure that doesnt matter if even or odd - it is floor so always rounds down\n",
    "            start = mid - 3\n",
    "            end = mid + 2\n",
    "    else:\n",
    "            mid = length // 2\n",
    "            start = mid - 2\n",
    "            end = mid + 3\n",
    "\n",
    "    return aa_string[start:end]\n",
    "\n",
    "\n",
    "def get_middle_five_right(aa_string):\n",
    "    if pd.isna(aa_string):  # Check for NaN/null values\n",
    "        return aa_string\n",
    "    length = len(aa_string)\n",
    "    \n",
    "    if( length % 2 == 0 ):\n",
    "            mid = length // 2 # integer division will ensure that doesnt matter if even or odd - it is floor so always rounds down\n",
    "            start = mid - 2\n",
    "            end = mid + 3\n",
    "    else:\n",
    "            mid = length // 2\n",
    "            start = mid - 2\n",
    "            end = mid + 3\n",
    "\n",
    "    return aa_string[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "back['CDR3A'] = back['CDR3A'].apply(get_middle_five_left)\n",
    "back['CDR3B'] = back['CDR3B'].apply(get_middle_five_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcr_info['CDR3A'] = tcr_info['CDR3A'].apply(get_middle_five_left)\n",
    "tcr_info['CDR3B'] = tcr_info['CDR3B'].apply(get_middle_five_left)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_translation(translation, spc, back, translate_epitope=False):\n",
    "    \n",
    "    spc = spc.copy()\n",
    "    back = back.copy()\n",
    "    translation_table = str.maketrans(translation)\n",
    "    \n",
    "    back['translation_alpha'] = back['CDR3A'].apply(lambda x: x.translate(translation_table))\n",
    "    back['translation_beta'] = back['CDR3B'].apply(lambda x: x.translate(translation_table))\n",
    "    spc['translation_alpha'] = spc['CDR3A'].apply(lambda x: x.translate(translation_table))\n",
    "    spc['translation_beta'] =  spc['CDR3B'].apply(lambda x: x.translate(translation_table))\n",
    "    \n",
    "    if translate_epitope: \n",
    "        spc['translation_epitope'] =  spc['epitope'].apply(lambda x: x.translate(translation_table))\n",
    "        return prs.renyi2_entropy(back, 'translation_alpha') + prs.renyi2_entropy(back, 'translation_beta') - prs.renyi2_entropy(spc, 'translation_alpha', 'translation_epitope') - prs.renyi2_entropy(spc, 'translation_beta', 'translation_epitope')\n",
    "    \n",
    "    else:\n",
    "        return prs.renyi2_entropy(back, 'translation_alpha') + prs.renyi2_entropy(back, 'translation_beta') - prs.renyi2_entropy(spc, 'translation_alpha', 'epitope') - prs.renyi2_entropy(spc, 'translation_beta', 'epitope')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_translation_from_list(aa_to_be_one):\n",
    "    \n",
    "    return {aa: '1' if aa in aa_to_be_one else '0' for aa in aminoacids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_algorithm(back, spc, translate_epitope=False):\n",
    "    \n",
    "    best_amino_acids_to_be_one = []\n",
    "    best_score = -np.inf\n",
    "    for i in range(20):\n",
    "        best_amino_acid_to_be_one = \"\"\n",
    "        best_local_score = -np.inf\n",
    "        for aa in aminoacids:\n",
    "            if aa not in best_amino_acids_to_be_one:\n",
    "                list_to_try = best_amino_acids_to_be_one.copy()\n",
    "                list_to_try.append(aa)\n",
    "                translation = make_translation_from_list(list_to_try)\n",
    "                score = evaluate_translation(translation, spc, back, translate_epitope)\n",
    "                \n",
    "                if score > best_local_score:\n",
    "                    best_amino_acid_to_be_one = aa\n",
    "                    best_local_score = score\n",
    "        \n",
    "        if best_local_score <= best_score:\n",
    "            print(\"Locally optimal set found\")\n",
    "            return best_amino_acids_to_be_one, best_score\n",
    "        \n",
    "        else:\n",
    "            print(f\"Improvement found, new score: {best_local_score:.1f} bits\")\n",
    "            best_score = best_local_score\n",
    "            best_amino_acids_to_be_one.append(best_amino_acid_to_be_one)\n",
    "            \n",
    "    return best_amino_acids_to_be_one, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on training data\n",
    "\n",
    "### Not translating the epitope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement found, new score: 4.0 bits\n",
      "Improvement found, new score: 5.6 bits\n",
      "Improvement found, new score: 6.6 bits\n",
      "Improvement found, new score: 6.9 bits\n",
      "Improvement found, new score: 7.0 bits\n",
      "Locally optimal set found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['G', 'S', 'R', 'T', 'E'],\n",
       " ['A', 'C', 'D', 'F', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'V', 'W', 'Y'],\n",
       " np.float64(7.031338940358852))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_1, score = greedy_algorithm(back, test)\n",
    "best_1, [aa for aa in aminoacids if aa not in best_1], score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.786727214329384)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_alphabet_1 = make_translation_from_list(best_1)\n",
    "translation_table_1 = str.maketrans(optimal_alphabet_1)\n",
    "back['translation_alpha'] = back['CDR3A'].apply(lambda x: x.translate(translation_table_1))\n",
    "back['translation_beta'] = back['CDR3B'].apply(lambda x: x.translate(translation_table_1))\n",
    "test['translation_alpha'] = test['CDR3A'].apply(lambda x: x.translate(translation_table_1))\n",
    "test['translation_beta'] = test['CDR3B'].apply(lambda x: x.translate(translation_table_1))\n",
    "test['translation_epitope'] = test['epitope'].apply(lambda x: x.translate(translation_table_1)) \n",
    "prs.renyi2_entropy(back, 'translation_alpha') + prs.renyi2_entropy(back, 'translation_beta') - prs.renyi2_entropy(test, 'translation_alpha', 'translation_epitope') - prs.renyi2_entropy(test, 'translation_beta', 'translation_epitope') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "translation_epitope\n",
       "11000    24495\n",
       "01000     6695\n",
       "00000     5278\n",
       "01010     3166\n",
       "10010     1188\n",
       "10000     1090\n",
       "00110      935\n",
       "01001      934\n",
       "10100      912\n",
       "00001      843\n",
       "00100      758\n",
       "00010      515\n",
       "01110      468\n",
       "00011      299\n",
       "01100      275\n",
       "11100      208\n",
       "01111      127\n",
       "11001      108\n",
       "10111      108\n",
       "00101       91\n",
       "11101       91\n",
       "11010       84\n",
       "10101       73\n",
       "10011       72\n",
       "01011       59\n",
       "10110       51\n",
       "10001       45\n",
       "00111       20\n",
       "01101       16\n",
       "11110       10\n",
       "11111        8\n",
       "11011        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['translation_epitope'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translating the epitope in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement found, new score: 2.8 bits\n",
      "Improvement found, new score: 3.4 bits\n",
      "Improvement found, new score: 4.6 bits\n",
      "Locally optimal set found\n"
     ]
    }
   ],
   "source": [
    "best_2, score = greedy_algorithm(back, test, translate_epitope=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['G', 'S', 'R'],\n",
       " ['A',\n",
       "  'C',\n",
       "  'D',\n",
       "  'E',\n",
       "  'F',\n",
       "  'H',\n",
       "  'I',\n",
       "  'K',\n",
       "  'L',\n",
       "  'M',\n",
       "  'N',\n",
       "  'P',\n",
       "  'Q',\n",
       "  'T',\n",
       "  'V',\n",
       "  'W',\n",
       "  'Y'],\n",
       " np.float64(4.649510063613695))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_2, [aa for aa in aminoacids if aa not in best_2], score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "epitope\n",
       "GGALQ    24201\n",
       "LGFVF     4734\n",
       "DRKSD     2984\n",
       "KFKQL     2459\n",
       "TDFSV     1083\n",
       "         ...  \n",
       "WDHNP        1\n",
       "TESLH        1\n",
       "SYTPV        1\n",
       "SSHLF        1\n",
       "TAMDI        1\n",
       "Name: count, Length: 946, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['epitope'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "translation_epitope\n",
       "11000    24365\n",
       "00000     7943\n",
       "01000     5666\n",
       "01010     3308\n",
       "10000     1812\n",
       "00100     1615\n",
       "00010     1499\n",
       "01001      839\n",
       "00001      485\n",
       "00110      408\n",
       "10100      209\n",
       "11100      180\n",
       "00111      124\n",
       "01100       94\n",
       "11001       75\n",
       "10010       70\n",
       "10011       61\n",
       "00011       55\n",
       "10101       51\n",
       "10110       50\n",
       "10001       33\n",
       "00101       21\n",
       "01101       17\n",
       "11101       14\n",
       "11010       14\n",
       "10111        6\n",
       "11111        2\n",
       "01110        2\n",
       "11011        2\n",
       "11110        2\n",
       "01111        1\n",
       "01011        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['translation_epitope'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4.649510063613695)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_alphabet_2 = make_translation_from_list(best_2)\n",
    "translation_table_2 = str.maketrans(optimal_alphabet_2)\n",
    "back['translation_alpha'] = back['CDR3A'].apply(lambda x: x.translate(translation_table_2))\n",
    "back['translation_beta'] = back['CDR3B'].apply(lambda x: x.translate(translation_table_2))\n",
    "test['translation_alpha'] = test['CDR3A'].apply(lambda x: x.translate(translation_table_2))\n",
    "test['translation_beta'] = test['CDR3B'].apply(lambda x: x.translate(translation_table_2))\n",
    "test['translation_epitope'] = test['epitope'].apply(lambda x: x.translate(translation_table_2)) \n",
    "prs.renyi2_entropy(back, 'translation_alpha') + prs.renyi2_entropy(back, 'translation_beta') - prs.renyi2_entropy(test, 'translation_alpha', 'translation_epitope') - prs.renyi2_entropy(test, 'translation_beta', 'translation_epitope') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on minervina and dash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
